{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b718058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fd8bf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Optional, List\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d89cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveLayer(nn.Module):\n",
    "    def __init__(self, F, in_chan, out_chan, stride, padding, block:\"NaiveBlock\"=None, set_residuals=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_chan, out_chan, F, stride, padding)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_chan, 1e-4, 0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.block = block\n",
    "        self.set_residuals = set_residuals\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv(X)\n",
    "        X = self.batch_norm(X)\n",
    "\n",
    "        if self.block is not None and self.block.residual is not None:\n",
    "            X += self.block.residual\n",
    "\n",
    "        if self.set_residuals == True:\n",
    "            self.block.residual = X\n",
    "        \n",
    "        X = self.relu(X)\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "class NaiveBlock(nn.Module):\n",
    "    residual: Optional[torch.Tensor]\n",
    "    def __init__(self,  init_chan, in_chan, Fs=[], stride=1, paddings=[], expansion=4, num_repeats=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.init_chan = init_chan\n",
    "        \n",
    "        sequence = []\n",
    "\n",
    "        self.register_buffer(\"residual\", None)\n",
    "        # TODO: ensure that the residual from the previous block is passed onto this block\n",
    "\n",
    "        for i in range(num_repeats):\n",
    "            for idx, F in enumerate(Fs):\n",
    "                if expansion is not None and idx == len(Fs) - 1:\n",
    "                    sequence.append(NaiveLayer(F, in_chan, in_chan*expansion, stride, paddings[idx], block=self))\n",
    "                    self.init_chan = in_chan*expansion\n",
    "                elif idx == 0 and i == 0:\n",
    "                    sequence.append(NaiveLayer(F, self.init_chan, in_chan, stride, paddings[idx], self, set_residuals=True))\n",
    "                elif idx == 0:\n",
    "                    sequence.append(NaiveLayer(F, self.init_chan, in_chan, stride, paddings[idx]))\n",
    "                else:\n",
    "                    sequence.append(NaiveLayer(F, in_chan, in_chan, stride, paddings[idx]))\n",
    "\n",
    "        self.sequence = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequence(X)\n",
    "\n",
    "\n",
    "class NaiveResNet50(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer(\"global_residual\", None)\n",
    "\n",
    "        self.conv1 = NaiveLayer(7, in_chan=3, out_chan=64, stride=2, padding=3)\n",
    "        self.conv2_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = NaiveBlock(init_chan=64, in_chan=64, Fs=[1,3,1], stride=1, paddings=[0,1,0], expansion=4, num_repeats=3)\n",
    "        self.conv3 = NaiveBlock(init_chan=256, in_chan=128, Fs=[1,3,1], stride=1, paddings=[0,1,0], expansion=4, num_repeats=4)\n",
    "        self.conv4 = NaiveBlock(init_chan=512, in_chan=256, Fs=[1,3,1], stride=1, paddings=[0,1,0], expansion=4, num_repeats=6)\n",
    "        self.conv5 = NaiveBlock(init_chan=1024, in_chan=512, Fs=[1,3,1], stride=1, paddings=[0,1,0], expansion=4, num_repeats=3)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(512*4, 1000) \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.conv2_pool(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.conv3(X)\n",
    "        X = self.conv4(X)\n",
    "        X = self.conv5(X)\n",
    "        X = self.avg_pool(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.fc(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95efd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4689dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, out_channels, repeats):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence = nn.Sequential(\n",
    "            *[nn.Conv2d(56 * 56 * out_channels, 56 * 56 * out_channels, kernel_size=1),\n",
    "            nn.Conv2d(56 * 56 * out_channels, 56 * 56 * out_channels, kernel_size=3, padding=1),\n",
    "            nn.Conv2d(56 * 56 * out_channels, 56 * 56 * out_channels*4, kernel_size=1) for i in range(repeats)],\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.sequence(X)\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                224 * 224 * 3, 112 * 112 * 64, kernel_size=7, stride=2, padding=3\n",
    "            )\n",
    "        self.bridge_pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv2 = block(64, 3)\n",
    "        self.conv3 = block(128, 4)\n",
    "        self.conv4 = block(256, 6)\n",
    "        self.conv5 = block(512, 3)\n",
    "        self.avg_pool = nn.AvgPool2d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return (chain(X)\n",
    "                (self.conv1)\n",
    "                (self.bridge_pool)\n",
    "                (self.conv1)\n",
    "                (self.conv2)\n",
    "                (self.conv3)\n",
    "                (self.conv4)\n",
    "                (self.conv5)\n",
    "                (self.avg_pool)())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        repeats: int,\n",
    "        # inner loop\n",
    "        out_chans: List[int],\n",
    "        kernel_sizes: List[int],\n",
    "        strides: List[int],\n",
    "        paddings: List[int],\n",
    "    ):\n",
    "        self.repeats = repeats\n",
    "\n",
    "        # inner loop\n",
    "        self.out_chans = out_chans\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, layers: List[Layer], output_cats: int = 1000):\n",
    "        super().__init__()\n",
    "        self.output_cats = output_cats\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Initial\n",
    "        self.conv_i = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn_conv_i = nn.BatchNorm2d(64)\n",
    "        self.max_pool_i = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        resnet_layers = []\n",
    "\n",
    "        curr_chan = 64\n",
    "\n",
    "        # Resnet\n",
    "        for layer_idx, layer in enumerate(layers):\n",
    "            for i in range(layer.repeats):\n",
    "                strides = (\n",
    "                    [1] * len(layer.strides) if layer_idx == 0 or i != 0 else layer.strides\n",
    "                )  # TODO: remove hardcoding like this\n",
    "\n",
    "                identity_chans = None\n",
    "\n",
    "                resnet_block = []\n",
    "                # inner loop\n",
    "                for j, _ in enumerate(layer.out_chans):\n",
    "                    if j == 0:\n",
    "                        in_chan = curr_chan  # input is the output of previous layer ï¼ˆfrom prev block)\n",
    "                        identity_chans = curr_chan\n",
    "                    else:\n",
    "                        in_chan = layer.out_chans[\n",
    "                            j - 1\n",
    "                        ]  # input is the output of previous layer\n",
    "\n",
    "                    conv_name = f\"{layer_idx}_{i}_{j}_conv\"\n",
    "                    bn_name = f\"{layer_idx}_{i}_{j}_bn\"\n",
    "\n",
    "                    setattr(\n",
    "                        self,\n",
    "                        conv_name,\n",
    "                        nn.Conv2d(\n",
    "                            in_chan,  # [64,64,64], [256,64,64] | [256,128,128], [512,128,128]\n",
    "                            layer.out_chans[j],  # [64,64,256] | [128,128,512]\n",
    "                            layer.kernel_sizes[j],  # [1,3,1]\n",
    "                            strides[j],  # [1,1,1] | [1,2,1]\n",
    "                            layer.paddings[j],  # [0,1,0]\n",
    "                            bias=False,  # no need bias as batch norm subtracts it (via the mean)\n",
    "                        ),\n",
    "                    )\n",
    "                    resnet_block.append(conv_name)\n",
    "                    setattr(self, bn_name, nn.BatchNorm2d(layer.out_chans[j]))\n",
    "                    resnet_block.append(bn_name)\n",
    "\n",
    "                    if j < len(layer.out_chans) - 1:\n",
    "                        resnet_block.append(\"relu\")\n",
    "\n",
    "                    curr_chan = layer.out_chans[j]\n",
    "\n",
    "                #   output         residuals\n",
    "                if curr_chan != identity_chans or max(strides) > 1:\n",
    "                    identity_downsample = [\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=identity_chans,\n",
    "                            out_channels=curr_chan,\n",
    "                            kernel_size=1,\n",
    "                            stride=max(strides),\n",
    "                            bias=False,  # if stride 2, then output is halved, so need to halve identity too\n",
    "                        ),\n",
    "                        nn.BatchNorm2d(curr_chan),\n",
    "                    ]\n",
    "\n",
    "                    ds_name = f\"{layer_idx}_{i}_ds\"\n",
    "                    setattr(self, ds_name, nn.Sequential(*identity_downsample))\n",
    "                    resnet_block.append(ds_name)\n",
    "                else:\n",
    "                    resnet_block.append(f\"{layer_idx}_{i}_identity\")\n",
    "\n",
    "                resnet_block.append(\"relu\")\n",
    "                resnet_layers.append(resnet_block)\n",
    "\n",
    "        self.resnet_layers = resnet_layers\n",
    "\n",
    "        # Ending\n",
    "        self.avg_pool_e = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(layers[-1].out_chans[-1], output_cats)\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        X = self.conv_i(X)\n",
    "        X = self.bn_conv_i(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool_i(X)\n",
    "\n",
    "        identity = None\n",
    "        for b_i, block in enumerate(self.resnet_layers):\n",
    "            for i, net_name in enumerate(block):\n",
    "                net = getattr(self, net_name, None)\n",
    "\n",
    "                if i == 0:\n",
    "                    identity = X\n",
    "\n",
    "                if \"ds\" in net_name:\n",
    "                    downsampled_identity = net(identity)\n",
    "                    X += downsampled_identity\n",
    "                    continue\n",
    "\n",
    "                if \"identity\" in net_name and net is None:\n",
    "                    X += identity\n",
    "                    continue\n",
    "\n",
    "                X = net(X)\n",
    "\n",
    "        X = self.avg_pool_e(X)\n",
    "        # [N, 2048, 1, 1]\n",
    "\n",
    "        X = X.flatten(1, 3)\n",
    "        # [N, 2048]\n",
    "\n",
    "        X = self.fc(X)\n",
    "        # [N, 1000]\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "resnet_18 = ResNet(\n",
    "    [\n",
    "        Layer(2, [64, 64], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(2, [128, 128], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(2, [256, 256], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(2, [512, 512], [3, 3], [2, 1], [1,1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_34 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(4, [128, 128], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(6, [256, 256], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(3, [512, 512], [3, 3], [2, 1], [1,1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_50 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(6, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_101 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(23, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_152 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(8, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(36, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "48c9a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        repeats: int,\n",
    "        # inner loop\n",
    "        out_chans: List[int],\n",
    "        kernel_sizes: List[int],\n",
    "        strides: List[int],\n",
    "        paddings: List[int],\n",
    "    ):\n",
    "        self.repeats = repeats\n",
    "\n",
    "        # inner loop\n",
    "        self.out_chans = out_chans\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.strides = strides\n",
    "        self.paddings = paddings\n",
    "\n",
    "\n",
    "class LayerNet(nn.Module):\n",
    "    def __init__(self, layer: Layer, layer_idx: int, prev_layer_chans: int):\n",
    "        super().__init__()\n",
    "\n",
    "        curr_chan = prev_layer_chans\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        resnet_procedure = []\n",
    "\n",
    "        for i in range(layer.repeats):\n",
    "            strides = (\n",
    "                [1] * len(layer.strides) if layer_idx == 0 or i != 0 else layer.strides\n",
    "            )  # TODO: remove hardcoding like this\n",
    "\n",
    "            identity_chans = None\n",
    "\n",
    "            resnet_block = []\n",
    "            # inner loop\n",
    "            for j, _ in enumerate(layer.out_chans):\n",
    "                if j == 0:\n",
    "                    in_chan = curr_chan  # input is the output of previous layer ï¼ˆfrom prev block)\n",
    "                    identity_chans = curr_chan\n",
    "                else:\n",
    "                    in_chan = layer.out_chans[\n",
    "                        j - 1\n",
    "                    ]  # input is the output of previous layer\n",
    "\n",
    "                conv = [\n",
    "                    nn.Conv2d(\n",
    "                        in_chan,  # [64,64,64], [256,64,64] | [256,128,128], [512,128,128]\n",
    "                        layer.out_chans[j],  # [64,64,256] | [128,128,512]\n",
    "                        layer.kernel_sizes[j],  # [1,3,1]\n",
    "                        strides[j],  # [1,1,1] | [1,2,1]\n",
    "                        layer.paddings[j],  # [0,1,0]\n",
    "                        bias=False,  # no need bias as batch norm subtracts it (via the mean)\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(layer.out_chans[j]),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                conv_sequential = (\n",
    "                    nn.Sequential(*conv)\n",
    "                    if j < len(layer.out_chans) - 1\n",
    "                    else nn.Sequential(*conv[:-1])\n",
    "                )\n",
    "                resnet_block.append(f\"{i}_{j}_conv\")\n",
    "                setattr(self, f\"{i}_{j}_conv\", conv_sequential)\n",
    "\n",
    "                curr_chan = layer.out_chans[j]\n",
    "\n",
    "            #   output         residuals\n",
    "            if curr_chan != identity_chans or max(strides) > 1:\n",
    "                identity_downsample = [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=identity_chans,\n",
    "                        out_channels=curr_chan,\n",
    "                        kernel_size=1,\n",
    "                        stride=max(strides),\n",
    "                        bias=False,  # if stride 2, then output is halved, so need to halve identity too\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(curr_chan),\n",
    "                ]\n",
    "\n",
    "                ds_name = f\"{layer_idx}_{i}_ds\"\n",
    "                setattr(self, ds_name, nn.Sequential(*identity_downsample))\n",
    "                resnet_block.append(ds_name)\n",
    "            else:\n",
    "                resnet_block.append(f\"{layer_idx}_{i}_identity\")\n",
    "\n",
    "            resnet_block.append(\"relu\")\n",
    "            resnet_procedure.append(resnet_block)\n",
    "\n",
    "        self.resnet_procedure = resnet_procedure\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self.resnet_procedure:\n",
    "            for i, net_name in enumerate(block):\n",
    "                net = getattr(self, net_name, None)\n",
    "\n",
    "                if i == 0:\n",
    "                    identity = X\n",
    "\n",
    "                if \"ds\" in net_name:\n",
    "                    downsampled_identity = net(identity)\n",
    "                    X += downsampled_identity\n",
    "                    continue\n",
    "\n",
    "                if \"identity\" in net_name and net is None:\n",
    "                    X += identity\n",
    "                    continue\n",
    "\n",
    "                X = net(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, layers: List[Layer], output_cats: int = 1000):\n",
    "        super().__init__()\n",
    "        self.output_cats = output_cats\n",
    "        self.layers = layers\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Initial\n",
    "        self.conv_i = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn_conv_i = nn.BatchNorm2d(64)\n",
    "        self.max_pool_i = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Resnet\n",
    "        for layer_idx, layer in enumerate(layers):\n",
    "            prev_layer_chans = (\n",
    "                64 if layer_idx == 0 else layers[layer_idx - 1].out_chans[-1]\n",
    "            )\n",
    "            setattr(\n",
    "                self, f\"layer_{layer_idx}\", LayerNet(layer, layer_idx, prev_layer_chans)\n",
    "            )\n",
    "\n",
    "        # Ending\n",
    "        self.avg_pool_e = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(layers[-1].out_chans[-1], output_cats)\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        X = self.conv_i(X)\n",
    "        X = self.bn_conv_i(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool_i(X)\n",
    "\n",
    "        for layer_idx, _ in enumerate(self.layers):\n",
    "            layer_net = getattr(self, f\"layer_{layer_idx}\")\n",
    "            X = layer_net(X)\n",
    "\n",
    "        X = self.avg_pool_e(X)\n",
    "        # [N, 2048, 1, 1]\n",
    "\n",
    "        X = X.flatten(1, 3)\n",
    "        # [N, 2048]\n",
    "\n",
    "        X = self.fc(X)\n",
    "        # [N, 1000]\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "resnet_18 = ResNet(\n",
    "    [\n",
    "        Layer(2, [64, 64], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(2, [128, 128], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(2, [256, 256], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(2, [512, 512], [3, 3], [2, 1], [1, 1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_34 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(4, [128, 128], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(6, [256, 256], [3, 3], [2, 1], [1, 1]),\n",
    "        Layer(3, [512, 512], [3, 3], [2, 1], [1, 1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_50 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(6, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_101 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(23, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "resnet_152 = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(8, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(36, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e02d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=train_transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"../data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bea5ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(20.878055214376165)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.log(0.95**90 * 0.05**10/ 0.50**90 * 0.50**10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fa79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in train_dataloader:\n",
    "    # print(X.shape)\n",
    "    # idx = 6\n",
    "    # plt.imshow(X[idx].permute(1,2,0))\n",
    "    # print(y[idx], train_data.classes[y[idx]])\n",
    "    \n",
    "    # to_classnames = lambda x: train_data.classes[x]\n",
    "    # with torch.no_grad():\n",
    "    #     pred = model(X)\n",
    "    #     pred_list = torch.argmax(pred, dim=1).detach().tolist()\n",
    "    #     pred_list = list(map(to_classnames, pred_list))\n",
    "    \n",
    "    # y_cn = list(map(to_classnames, y))\n",
    "    # for i, p in enumerate(pred_list):\n",
    "    #     plt.imshow(X[i].permute(1,2,0))\n",
    "    #     plt.show()\n",
    "    #     print(f\"Answer: {y_cn[i]}, pred: {p}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d9ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 2 (460439618.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[197]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmodel = ResNet(\u001b[39m\n                   ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'for' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "def train(model, data, optimizer: torch.optim.AdamW, loss_func: nn.CrossEntropyLoss):\n",
    "    for X, y in data:\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_func(pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test(model, data, loss_func: nn.CrossEntropyLoss):\n",
    "    for X, y in data:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred,y)\n",
    "\n",
    "\n",
    "\n",
    "model = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(4, [128, 128], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(6, [256, 256], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(3, [512, 512], [3, 3], [2, 1], [1,1]),\n",
    "    ], output_cats=10\n",
    ")\n",
    "\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for i in range(epochs):\n",
    "    train(model, train_dataloader, optimizer, loss_func)\n",
    "    test(model, test_dataloader, loss_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bbf3e64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "import os\n",
    "\n",
    "# improved training loop with nice progress, TensorBoard logging, live matplotlib plots and checkpointing\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# prepare model, loss, optimizer, scheduler\n",
    "model = ResNet(\n",
    "    [\n",
    "        Layer(3, [64, 64], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(4, [128, 128], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(6, [256, 256], [3, 3], [2, 1], [1,1]),\n",
    "        Layer(3, [512, 512], [3, 3], [2, 1], [1,1]),\n",
    "    ], output_cats=10\n",
    ").to(device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = torch.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "# TensorBoard writer\n",
    "log_dir = \"runs/resnet_experiment\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# live plot setup\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "def _plot_progress():\n",
    "    clear_output(wait=True)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "    axes[0].plot(train_losses, label=\"train\")\n",
    "    axes[0].plot(val_losses, label=\"val\")\n",
    "    axes[0].set_title(\"Loss\"); axes[0].legend()\n",
    "    axes[1].plot(train_accs, label=\"train\")\n",
    "    axes[1].plot(val_accs, label=\"val\")\n",
    "    axes[1].set_title(\"Accuracy\"); axes[1].legend()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, loss_func, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(dataloader, desc=f\"Train {epoch}\", leave=False)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in pbar:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(X)\n",
    "                loss = loss_func(pred, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        _, preds = pred.max(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += X.size(0)\n",
    "\n",
    "        pbar.set_postfix(loss=running_loss/total, acc=100*correct/total, lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def eval_epoch(model, dataloader, loss_func, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=f\"Eval {epoch}\", leave=False)\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_func(pred, y)\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "            _, preds = pred.max(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += X.size(0)\n",
    "            pbar.set_postfix(loss=running_loss/total, acc=100*correct/total)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# training loop\n",
    "epochs = 10\n",
    "best_val_acc = 0.0\n",
    "ckpt_dir = \"checkpoints\"\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_epoch(model, train_dataloader, optimizer, loss_func, epoch)\n",
    "    val_loss, val_acc = eval_epoch(model, test_dataloader, loss_func, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    train_losses.append(train_loss); val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc); val_accs.append(val_acc)\n",
    "\n",
    "    # TensorBoard logging\n",
    "    writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "    writer.add_scalar(\"LR\", optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "    # save best checkpoint\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\"model_state\": model.state_dict(), \"optimizer_state\": optimizer.state_dict(), \"epoch\": epoch, \"val_acc\": val_acc},\n",
    "                   os.path.join(ckpt_dir, \"best.pth\"))\n",
    "\n",
    "    # print & live plot\n",
    "    print(f\"Epoch {epoch}/{epochs} - {time.time()-t0:.1f}s - train_loss {train_loss:.4f} train_acc {train_acc:.2f}% - val_loss {val_loss:.4f} val_acc {val_acc:.2f}% (best {best_val_acc:.2f}%)\")\n",
    "    _plot_progress()\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a8720449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "\n",
    "# testing shapes\n",
    "img = torch.randn(1, 3, 224, 224)\n",
    "res = resnet_50(img)\n",
    "res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "34876d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (relu): ReLU()\n",
       "  (conv_i): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn_conv_i): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool_i): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer_0): LayerNet(\n",
       "    (relu): ReLU()\n",
       "    (0_0_conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_1_conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_2_conv): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (0_0_ds): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1_0_conv): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_1_conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_2_conv): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2_0_conv): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_1_conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_2_conv): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_1): LayerNet(\n",
       "    (relu): ReLU()\n",
       "    (0_0_conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_1_conv): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_2_conv): Sequential(\n",
       "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1_0_ds): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1_0_conv): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_1_conv): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_2_conv): Sequential(\n",
       "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2_0_conv): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_1_conv): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_2_conv): Sequential(\n",
       "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3_0_conv): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3_1_conv): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3_2_conv): Sequential(\n",
       "      (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_2): LayerNet(\n",
       "    (relu): ReLU()\n",
       "    (0_0_conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2_0_ds): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (5_1_conv): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (5_2_conv): Sequential(\n",
       "      (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_3): LayerNet(\n",
       "    (relu): ReLU()\n",
       "    (0_0_conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_1_conv): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (0_2_conv): Sequential(\n",
       "      (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3_0_ds): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1_0_conv): Sequential(\n",
       "      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_1_conv): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1_2_conv): Sequential(\n",
       "      (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2_0_conv): Sequential(\n",
       "      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_1_conv): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2_2_conv): Sequential(\n",
       "      (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool_e): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cf50e",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "37cde5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18: params â‰ˆ 11.69M, output (2, 1000)\n",
      "resnet34: params â‰ˆ 21.80M, output (2, 1000)\n",
      "resnet50: params â‰ˆ 25.56M, output (2, 1000)\n",
      "resnet101: params â‰ˆ 44.55M, output (2, 1000)\n",
      "resnet152: params â‰ˆ 60.19M, output (2, 1000)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Type, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"ResNet BasicBlock for 18/34. Stride applied to the FIRST 3x3.\"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Type[nn.Module] = nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, 1)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "        # Zero-init last BN so block starts as identity.\n",
    "        nn.init.constant_(self.bn2.weight, 0.0)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet Bottleneck for 50/101/152 (v1.5: stride on the 3x3).\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        norm_layer: Type[nn.Module] = nn.BatchNorm2d,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes, 1)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)  # v1.5: stride here\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion, 1)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "        # Zero-init last BN so block starts as identity.\n",
    "        nn.init.constant_(self.bn3.weight, 0.0)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StageConfig:\n",
    "    \"\"\"One ResNet stage (a stack of identical blocks).\"\"\"\n",
    "    block: Type[nn.Module]  # BasicBlock or Bottleneck\n",
    "    planes: int             # inner channels for the block (64/128/256/512)\n",
    "    num_blocks: int         # number of blocks in the stage\n",
    "    stride: int             # stride for the FIRST block in the stage\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"Configurable ResNet with explicit blocks and ModuleList stages.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        stages: List[StageConfig],\n",
    "        num_classes: int = 1000,\n",
    "        norm_layer: Type[nn.Module] = nn.BatchNorm2d,\n",
    "        zero_init_residual: bool = True,  # kept True by default as suggested\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.norm_layer = norm_layer\n",
    "\n",
    "        # Stem\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Stages\n",
    "        self.stages = nn.ModuleList()\n",
    "        for cfg in stages:\n",
    "            stage = self._make_layer(cfg.block, cfg.planes, cfg.num_blocks, stride=cfg.stride, norm_layer=norm_layer)\n",
    "            self.stages.append(stage)\n",
    "\n",
    "        # Head\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.inplanes, num_classes)\n",
    "\n",
    "        # Optionally zero-init last BN was already done inside blocks\n",
    "        # Here we could also Kaiming-init convs if needed\n",
    "        if zero_init_residual:\n",
    "            pass\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[nn.Module],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int,\n",
    "        norm_layer: Type[nn.Module],\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        out_channels = planes * block.expansion\n",
    "\n",
    "        if stride != 1 or self.inplanes != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, out_channels, stride),\n",
    "                norm_layer(out_channels),\n",
    "            )\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, norm_layer))\n",
    "        self.inplanes = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, 1, None, norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Factory helpers (canonical configs)\n",
    "def resnet18(num_classes: int = 1000) -> ResNet:\n",
    "    stages = [\n",
    "        StageConfig(BasicBlock, 64, 2, 1),\n",
    "        StageConfig(BasicBlock, 128, 2, 2),\n",
    "        StageConfig(BasicBlock, 256, 2, 2),\n",
    "        StageConfig(BasicBlock, 512, 2, 2),\n",
    "    ]\n",
    "    return ResNet(stages, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def resnet34(num_classes: int = 1000) -> ResNet:\n",
    "    stages = [\n",
    "        StageConfig(BasicBlock, 64, 3, 1),\n",
    "        StageConfig(BasicBlock, 128, 4, 2),\n",
    "        StageConfig(BasicBlock, 256, 6, 2),\n",
    "        StageConfig(BasicBlock, 512, 3, 2),\n",
    "    ]\n",
    "    return ResNet(stages, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def resnet50(num_classes: int = 1000) -> ResNet:\n",
    "    stages = [\n",
    "        StageConfig(Bottleneck, 64, 3, 1),\n",
    "        StageConfig(Bottleneck, 128, 4, 2),\n",
    "        StageConfig(Bottleneck, 256, 6, 2),\n",
    "        StageConfig(Bottleneck, 512, 3, 2),\n",
    "    ]\n",
    "    return ResNet(stages, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def resnet101(num_classes: int = 1000) -> ResNet:\n",
    "    stages = [\n",
    "        StageConfig(Bottleneck, 64, 3, 1),\n",
    "        StageConfig(Bottleneck, 128, 4, 2),\n",
    "        StageConfig(Bottleneck, 256, 23, 2),\n",
    "        StageConfig(Bottleneck, 512, 3, 2),\n",
    "    ]\n",
    "    return ResNet(stages, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def resnet152(num_classes: int = 1000) -> ResNet:\n",
    "    stages = [\n",
    "        StageConfig(Bottleneck, 64, 3, 1),\n",
    "        StageConfig(Bottleneck, 128, 8, 2),\n",
    "        StageConfig(Bottleneck, 256, 36, 2),\n",
    "        StageConfig(Bottleneck, 512, 3, 2),\n",
    "    ]\n",
    "    return ResNet(stages, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Quick smoke test\n",
    "def _count_params(m: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "\n",
    "def _test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    builders = [resnet18, resnet34, resnet50, resnet101, resnet152]\n",
    "\n",
    "    for build in builders:\n",
    "        model = build(num_classes=1000).to(device)\n",
    "        x = torch.randn(2, 3, 224, 224, device=device)\n",
    "        y = model(x)\n",
    "        assert y.shape == (2, 1000), f\"Bad output shape for {build.__name__}: {y.shape}\"\n",
    "        params_m = _count_params(model) / 1e6\n",
    "        print(f\"{build.__name__}: params â‰ˆ {params_m:.2f}M, output {tuple(y.shape)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4b93ef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (stages): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "de50a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export \n",
    "\n",
    "nb_export('resnet.ipynb', '../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35982852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
