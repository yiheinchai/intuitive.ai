# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/resnet.ipynb.

# %% auto 0
__all__ = ['resnet_18', 'resnet_34', 'resnet_50', 'resnet_101', 'resnet_152', 'train_transform', 'test_transform', 'train_data',
           'test_data', 'train_dataloader', 'test_dataloader', 'img', 'res', 'Layer', 'LayerNet', 'ResNet']

# %% ../notebooks/resnet.ipynb 1
import torch
from torch import nn
from typing import Optional, List

import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

import matplotlib.pyplot as plt

# %% ../notebooks/resnet.ipynb 6
class Layer:
    def __init__(
        self,
        repeats: int,
        # inner loop
        out_chans: List[int],
        kernel_sizes: List[int],
        strides: List[int],
        paddings: List[int],
    ):
        self.repeats = repeats

        # inner loop
        self.out_chans = out_chans
        self.kernel_sizes = kernel_sizes
        self.strides = strides
        self.paddings = paddings


class LayerNet(nn.Module):
    def __init__(self, layer: Layer, layer_idx: int, prev_layer_chans: int):
        super().__init__()

        curr_chan = prev_layer_chans
        self.relu = nn.ReLU()

        resnet_procedure = []

        for i in range(layer.repeats):
            strides = (
                [1] * len(layer.strides) if layer_idx == 0 or i != 0 else layer.strides
            )  # TODO: remove hardcoding like this

            identity_chans = None

            resnet_block = []
            # inner loop
            for j, _ in enumerate(layer.out_chans):
                if j == 0:
                    in_chan = curr_chan  # input is the output of previous layer ï¼ˆfrom prev block)
                    identity_chans = curr_chan
                else:
                    in_chan = layer.out_chans[
                        j - 1
                    ]  # input is the output of previous layer

                conv = [
                    nn.Conv2d(
                        in_chan,  # [64,64,64], [256,64,64] | [256,128,128], [512,128,128]
                        layer.out_chans[j],  # [64,64,256] | [128,128,512]
                        layer.kernel_sizes[j],  # [1,3,1]
                        strides[j],  # [1,1,1] | [1,2,1]
                        layer.paddings[j],  # [0,1,0]
                        bias=False,  # no need bias as batch norm subtracts it (via the mean)
                    ),
                    nn.BatchNorm2d(layer.out_chans[j]),
                    nn.ReLU(),
                ]
                conv_sequential = (
                    nn.Sequential(*conv)
                    if j < len(layer.out_chans) - 1
                    else nn.Sequential(*conv[:-1])
                )
                resnet_block.append(f"{i}_{j}_conv")
                setattr(self, f"{i}_{j}_conv", conv_sequential)

                curr_chan = layer.out_chans[j]

            #   output         residuals
            if curr_chan != identity_chans or max(strides) > 1:
                identity_downsample = [
                    nn.Conv2d(
                        in_channels=identity_chans,
                        out_channels=curr_chan,
                        kernel_size=1,
                        stride=max(strides),
                        bias=False,  # if stride 2, then output is halved, so need to halve identity too
                    ),
                    nn.BatchNorm2d(curr_chan),
                ]

                ds_name = f"{layer_idx}_{i}_ds"
                setattr(self, ds_name, nn.Sequential(*identity_downsample))
                resnet_block.append(ds_name)
            else:
                resnet_block.append(f"{layer_idx}_{i}_identity")

            resnet_block.append("relu")
            resnet_procedure.append(resnet_block)

        self.resnet_procedure = resnet_procedure

    def forward(self, X):
        for block in self.resnet_procedure:
            for i, net_name in enumerate(block):
                net = getattr(self, net_name, None)

                if i == 0:
                    identity = X

                if "ds" in net_name:
                    downsampled_identity = net(identity)
                    X += downsampled_identity
                    continue

                if "identity" in net_name and net is None:
                    X += identity
                    continue

                X = net(X)
        return X


class ResNet(nn.Module):
    def __init__(self, layers: List[Layer], output_cats: int = 1000):
        super().__init__()
        self.output_cats = output_cats
        self.layers = layers

        self.relu = nn.ReLU()

        # Initial
        self.conv_i = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn_conv_i = nn.BatchNorm2d(64)
        self.max_pool_i = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # Resnet
        for layer_idx, layer in enumerate(layers):
            prev_layer_chans = (
                64 if layer_idx == 0 else layers[layer_idx - 1].out_chans[-1]
            )
            setattr(
                self, f"layer_{layer_idx}", LayerNet(layer, layer_idx, prev_layer_chans)
            )

        # Ending
        self.avg_pool_e = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(layers[-1].out_chans[-1], output_cats)

    def forward(self, X: torch.Tensor):
        X = self.conv_i(X)
        X = self.bn_conv_i(X)
        X = self.relu(X)
        X = self.max_pool_i(X)

        for layer_idx, _ in enumerate(self.layers):
            layer_net = getattr(self, f"layer_{layer_idx}")
            X = layer_net(X)

        X = self.avg_pool_e(X)
        # [N, 2048, 1, 1]

        X = X.flatten(1, 3)
        # [N, 2048]

        X = self.fc(X)
        # [N, 1000]

        return X


resnet_18 = ResNet(
    [
        Layer(2, [64, 64], [3, 3], [2, 1], [1, 1]),
        Layer(2, [128, 128], [3, 3], [2, 1], [1, 1]),
        Layer(2, [256, 256], [3, 3], [2, 1], [1, 1]),
        Layer(2, [512, 512], [3, 3], [2, 1], [1, 1]),
    ]
)

resnet_34 = ResNet(
    [
        Layer(3, [64, 64], [3, 3], [2, 1], [1, 1]),
        Layer(4, [128, 128], [3, 3], [2, 1], [1, 1]),
        Layer(6, [256, 256], [3, 3], [2, 1], [1, 1]),
        Layer(3, [512, 512], [3, 3], [2, 1], [1, 1]),
    ]
)

resnet_50 = ResNet(
    [
        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(6, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
    ]
)

resnet_101 = ResNet(
    [
        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(4, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(23, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
    ]
)

resnet_152 = ResNet(
    [
        Layer(3, [64, 64, 256], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(8, [128, 128, 512], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(36, [256, 256, 1024], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
        Layer(3, [512, 512, 2048], [1, 3, 1], [1, 2, 1], [0, 1, 0]),
    ]
)

# %% ../notebooks/resnet.ipynb 7
train_transform = transforms.Compose(
    [
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ]
)
test_transform = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ]
)

train_data = torchvision.datasets.CIFAR10(root="../data", train=True, download=True, transform=train_transform)
test_data = torchvision.datasets.CIFAR10(root="../data", train=False, download=True, transform=test_transform)


train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(test_data, batch_size=64)


# %% ../notebooks/resnet.ipynb 12
# testing shapes
img = torch.randn(1, 3, 224, 224)
res = resnet_50(img)
res.shape

